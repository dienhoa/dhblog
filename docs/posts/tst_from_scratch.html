<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Dien-Hoa Truong">
<meta name="dcterms.date" content="2023-04-26">

<title>dhblog - Transformer for timeseries</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">dhblog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/DienhoaT"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/dien-hoa-truong-74449aa4/"><i class="bi bi-linkedin" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/dienhoa"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Transformer for timeseries</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">timeseries</div>
                <div class="quarto-category">deeplearning</div>
                <div class="quarto-category">transformer</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Dien-Hoa Truong </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 26, 2023</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Developing an Intuition for Transformers and Applying Them to Time Series Classification</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://pytorch.org/tutorials/_images/transformer_architecture.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Transformer Architecture</figcaption><p></p>
</figure>
</div>
<p>Struggling to learn a new deep learning architecture, such as Transformer, can be quite challenging. However, it doesn’t have to be so daunting. In this blog post, I will demonstrate a practical approach to start using a new architecture, specifically the Transformer. We will construct a basic Transformer architecture and progressively fine-tune it to achieve the performance of the TST architecture (A Transformer-based Framework for Multivariate Time Series Representation Learning).</p>
<p><strong>Content:</strong></p>
<ul>
<li>Dataset to use: <a href="https://www.timeseriesclassification.com/description.php?Dataset=FaceDetection">FaceDetection</a></li>
<li>Reference Model: <a href="https://timeseriesai.github.io/tsai/models.tst.html">TST Model</a> implemented in tsai repository</li>
<li>Baseline Model: LSTM Model</li>
<li>Our TST Model</li>
</ul>
<p><strong>References:</strong></p>
<ul>
<li><a href="https://github.com/timeseriesAI/tsai">tsai repository</a></li>
<li><a href="https://colab.research.google.com/github/timeseriesAI/tsai/blob/master/tutorial_nbs/07_Time_Series_Classification_with_Transformers.ipynb">How to use Transformers with TimeSeries Tutorial</a></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="op">-</span>Uqq tsai</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.data.core <span class="im">import</span> DataLoader, DataLoaders</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.learner <span class="im">import</span> Learner</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.losses <span class="im">import</span> LabelSmoothingCrossEntropyFlat</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.metrics <span class="im">import</span> RocAucBinary, accuracy</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.torch_core <span class="im">import</span> Module</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tsai.models.TST <span class="im">import</span> TST</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tsai.models.RNN <span class="im">import</span> LSTM</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tsai.data.external <span class="im">import</span> get_UCR_data</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tsai.callback.core <span class="im">import</span> ShowGraph <span class="im">as</span> ShowGraphCallback2</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tsai.learner <span class="im">import</span> plot_metrics</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="dataset-facedetection" class="level2">
<h2 class="anchored" data-anchor-id="dataset-facedetection">Dataset: <a href="https://www.timeseriesclassification.com/description.php?Dataset=FaceDetection">FaceDetection</a></h2>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Why Time Series? Although the Transformer originates from the NLP domain and outperforms all previous architectures, I believe that, for those not yet familiar with NLP, it is more advantageous to start with a domain that requires less preprocessing, such as Time Series. This way, we can focus our attention on understanding the architecture itself.</p>
</div>
</div>
<p>In this tutorial, we will be using a dataset from the well-known UEA &amp; UCR Time Series repository. Although we won’t delve into the details of this dataset in this blog post, it’s worth mentioning its purpose. The objective is to classify whether a given MEG signal (Magnetoencephalography) represents a face or not. The input dimension is 144, and the sequence length is 62.</p>
<p>I chose this dataset because it contains a reasonable amount of data (5,890 training instances and 3,524 testing instances) and has been used in a Transformer tutorial in the tsai repository. This ensures that we have a reliable reference model to aim to outperform.</p>
<p>We will utilize utility functions from the tsai and fastai libraries to facilitate our work and streamline the process.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>batch_size, c_in, c_out, seq_len <span class="op">=</span> <span class="dv">64</span>, <span class="dv">144</span>, <span class="dv">2</span>, <span class="dv">62</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>X, y, splits <span class="op">=</span> get_UCR_data(<span class="st">'FaceDetection'</span>, return_split<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> X[splits[<span class="dv">0</span>]]</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> y[splits[<span class="dv">0</span>]]</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>X_valid <span class="op">=</span> X[splits[<span class="dv">1</span>]]</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>y_valid <span class="op">=</span> y[splits[<span class="dv">1</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TSDataset(Dataset):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""TimeSeries DataSet for FaceDetection"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, X, y):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(TSDataset, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> torch.tensor(X)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Y <span class="op">=</span> torch.concat([torch.tensor([_y <span class="op">==</span> <span class="st">'0'</span>], dtype<span class="op">=</span><span class="bu">int</span>) <span class="cf">for</span> _y <span class="kw">in</span> y])</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>): <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.X)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, i):</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.X[i], <span class="va">self</span>.Y[i]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following code demonstrates how to create data loaders for the training and validation sets:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>dset_train <span class="op">=</span> TSDataset(X_train, y_train)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>dset_valid <span class="op">=</span> TSDataset(X_valid, y_valid)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>dl_train <span class="op">=</span> DataLoader(dset_train, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>dl_valid <span class="op">=</span> DataLoader(dset_valid, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> DataLoaders(dl_train, dl_valid) </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> dls.cuda()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>x, y <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(dl_train))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>x.shape, y.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>(torch.Size([64, 144, 62]), torch.Size([64]))</code></pre>
</div>
</div>
</section>
<section id="reference-model" class="level2">
<h2 class="anchored" data-anchor-id="reference-model">Reference Model</h2>
<p>The reference model we will be using is the <a href="https://arxiv.org/abs/2010.02803">TST</a> (Transformer-based Framework for Multivariate Time Series Representation Learning) and implemented by the tsai library.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>LabelSmoothingCrossEntropyFlat(), </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>                    metrics<span class="op">=</span>[RocAucBinary(), accuracy],  cbs<span class="op">=</span>ShowGraphCallback2())</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    learn.fit_one_cycle(<span class="dv">30</span>, <span class="fl">1e-4</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> TST(c_in, c_out, seq_len, dropout<span class="op">=</span><span class="fl">0.3</span>, fc_dropout<span class="op">=</span><span class="fl">0.9</span>,n_heads<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>TST(
  (W_P): Linear(in_features=144, out_features=128, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
  (encoder): _TSTEncoder(
    (layers): ModuleList(
      (0): _TSTEncoderLayer(
        (self_attn): _MultiHeadAttention(
          (W_Q): Linear(in_features=128, out_features=128, bias=False)
          (W_K): Linear(in_features=128, out_features=128, bias=False)
          (W_V): Linear(in_features=128, out_features=128, bias=False)
          (W_O): Linear(in_features=128, out_features=128, bias=False)
        )
        (dropout_attn): Dropout(p=0.3, inplace=False)
        (batchnorm_attn): Sequential(
          (0): Transpose(1, 2)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Transpose(1, 2)
        )
        (ff): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): GELU(approximate=none)
          (2): Dropout(p=0.3, inplace=False)
          (3): Linear(in_features=256, out_features=128, bias=True)
        )
        (dropout_ffn): Dropout(p=0.3, inplace=False)
        (batchnorm_ffn): Sequential(
          (0): Transpose(1, 2)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Transpose(1, 2)
        )
      )
      (1): _TSTEncoderLayer(
        (self_attn): _MultiHeadAttention(
          (W_Q): Linear(in_features=128, out_features=128, bias=False)
          (W_K): Linear(in_features=128, out_features=128, bias=False)
          (W_V): Linear(in_features=128, out_features=128, bias=False)
          (W_O): Linear(in_features=128, out_features=128, bias=False)
        )
        (dropout_attn): Dropout(p=0.3, inplace=False)
        (batchnorm_attn): Sequential(
          (0): Transpose(1, 2)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Transpose(1, 2)
        )
        (ff): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): GELU(approximate=none)
          (2): Dropout(p=0.3, inplace=False)
          (3): Linear(in_features=256, out_features=128, bias=True)
        )
        (dropout_ffn): Dropout(p=0.3, inplace=False)
        (batchnorm_ffn): Sequential(
          (0): Transpose(1, 2)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Transpose(1, 2)
        )
      )
      (2): _TSTEncoderLayer(
        (self_attn): _MultiHeadAttention(
          (W_Q): Linear(in_features=128, out_features=128, bias=False)
          (W_K): Linear(in_features=128, out_features=128, bias=False)
          (W_V): Linear(in_features=128, out_features=128, bias=False)
          (W_O): Linear(in_features=128, out_features=128, bias=False)
        )
        (dropout_attn): Dropout(p=0.3, inplace=False)
        (batchnorm_attn): Sequential(
          (0): Transpose(1, 2)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Transpose(1, 2)
        )
        (ff): Sequential(
          (0): Linear(in_features=128, out_features=256, bias=True)
          (1): GELU(approximate=none)
          (2): Dropout(p=0.3, inplace=False)
          (3): Linear(in_features=256, out_features=128, bias=True)
        )
        (dropout_ffn): Dropout(p=0.3, inplace=False)
        (batchnorm_ffn): Sequential(
          (0): Transpose(1, 2)
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): Transpose(1, 2)
        )
      )
    )
  )
  (flatten): fastai.layers.Flatten(full=False)
  (head): Sequential(
    (0): GELU(approximate=none)
    (1): fastai.layers.Flatten(full=False)
    (2): Dropout(p=0.9, inplace=False)
    (3): Linear(in_features=7936, out_features=2, bias=True)
  )
)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>evaluate_model(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>roc_auc_score</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.951646</td>
      <td>0.708477</td>
      <td>0.506569</td>
      <td>0.508229</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.970950</td>
      <td>0.704351</td>
      <td>0.516325</td>
      <td>0.513621</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.938998</td>
      <td>0.702305</td>
      <td>0.532927</td>
      <td>0.520715</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.921369</td>
      <td>0.691450</td>
      <td>0.571081</td>
      <td>0.551930</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.900328</td>
      <td>0.681608</td>
      <td>0.611268</td>
      <td>0.576617</td>
      <td>00:02</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.863914</td>
      <td>0.674634</td>
      <td>0.637967</td>
      <td>0.599035</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.823749</td>
      <td>0.668968</td>
      <td>0.661042</td>
      <td>0.613791</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.779181</td>
      <td>0.661584</td>
      <td>0.679245</td>
      <td>0.628831</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.773248</td>
      <td>0.655216</td>
      <td>0.689473</td>
      <td>0.641600</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.736231</td>
      <td>0.656833</td>
      <td>0.693580</td>
      <td>0.639614</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.706511</td>
      <td>0.645284</td>
      <td>0.703624</td>
      <td>0.648411</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.683176</td>
      <td>0.643659</td>
      <td>0.705447</td>
      <td>0.646708</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.683701</td>
      <td>0.640990</td>
      <td>0.709720</td>
      <td>0.654370</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.679145</td>
      <td>0.640454</td>
      <td>0.711721</td>
      <td>0.656924</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.675339</td>
      <td>0.638911</td>
      <td>0.715064</td>
      <td>0.660329</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.646258</td>
      <td>0.636575</td>
      <td>0.719171</td>
      <td>0.659762</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.640599</td>
      <td>0.634601</td>
      <td>0.721944</td>
      <td>0.662883</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.635253</td>
      <td>0.633066</td>
      <td>0.724559</td>
      <td>0.663167</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.627964</td>
      <td>0.630649</td>
      <td>0.727147</td>
      <td>0.668842</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.636265</td>
      <td>0.630882</td>
      <td>0.727375</td>
      <td>0.666856</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>20</td>
      <td>0.626629</td>
      <td>0.629530</td>
      <td>0.729055</td>
      <td>0.669694</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>21</td>
      <td>0.621701</td>
      <td>0.629509</td>
      <td>0.730594</td>
      <td>0.669410</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>22</td>
      <td>0.618601</td>
      <td>0.628475</td>
      <td>0.731707</td>
      <td>0.671112</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>23</td>
      <td>0.615214</td>
      <td>0.628622</td>
      <td>0.731949</td>
      <td>0.671112</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>24</td>
      <td>0.608272</td>
      <td>0.628038</td>
      <td>0.732958</td>
      <td>0.673383</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>25</td>
      <td>0.605929</td>
      <td>0.627823</td>
      <td>0.732090</td>
      <td>0.667707</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>26</td>
      <td>0.615131</td>
      <td>0.627309</td>
      <td>0.732836</td>
      <td>0.669126</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>27</td>
      <td>0.601275</td>
      <td>0.626884</td>
      <td>0.733086</td>
      <td>0.671112</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>28</td>
      <td>0.604665</td>
      <td>0.627029</td>
      <td>0.732831</td>
      <td>0.670545</td>
      <td>00:03</td>
    </tr>
    <tr>
      <td>29</td>
      <td>0.598579</td>
      <td>0.627305</td>
      <td>0.732970</td>
      <td>0.669977</td>
      <td>00:03</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">
<p><img src="tst_from_scratch_files/figure-html/cell-12-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="tst_from_scratch_files/figure-html/cell-12-output-4.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="baseline" class="level2">
<h2 class="anchored" data-anchor-id="baseline">Baseline</h2>
<p>We’ll begin our journey by exploring an LSTM model, which was commonly used for sequence classification in the pre-transformer era.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note: Observing the validation loss may lead you to believe that the model is overfitting. However, this is not the case, as the final metric (accuracy) continues to increase.</p>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LSTM(<span class="dv">144</span>,<span class="dv">2</span>,rnn_dropout<span class="op">=</span><span class="fl">0.3</span>, fc_dropout<span class="op">=</span><span class="fl">0.3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>evaluate_model(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>roc_auc_score</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.692997</td>
      <td>0.693003</td>
      <td>0.526605</td>
      <td>0.511067</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.694864</td>
      <td>0.692550</td>
      <td>0.530198</td>
      <td>0.509932</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.693224</td>
      <td>0.691885</td>
      <td>0.535819</td>
      <td>0.516459</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.690924</td>
      <td>0.690888</td>
      <td>0.544076</td>
      <td>0.534052</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.688154</td>
      <td>0.689443</td>
      <td>0.553810</td>
      <td>0.543417</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.681766</td>
      <td>0.688379</td>
      <td>0.560746</td>
      <td>0.540863</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.673015</td>
      <td>0.687371</td>
      <td>0.567939</td>
      <td>0.544835</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.667395</td>
      <td>0.686460</td>
      <td>0.576245</td>
      <td>0.546822</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.657265</td>
      <td>0.686633</td>
      <td>0.581978</td>
      <td>0.556470</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.648530</td>
      <td>0.689491</td>
      <td>0.584129</td>
      <td>0.560726</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.637290</td>
      <td>0.689848</td>
      <td>0.595202</td>
      <td>0.570091</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.622282</td>
      <td>0.692667</td>
      <td>0.603976</td>
      <td>0.573496</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.598900</td>
      <td>0.695254</td>
      <td>0.614031</td>
      <td>0.579739</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.593199</td>
      <td>0.695645</td>
      <td>0.623152</td>
      <td>0.583995</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.575668</td>
      <td>0.694726</td>
      <td>0.631737</td>
      <td>0.588820</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.565752</td>
      <td>0.696615</td>
      <td>0.635271</td>
      <td>0.595346</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.551287</td>
      <td>0.700495</td>
      <td>0.637275</td>
      <td>0.597049</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.546571</td>
      <td>0.703546</td>
      <td>0.638789</td>
      <td>0.593927</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.543675</td>
      <td>0.704447</td>
      <td>0.641093</td>
      <td>0.595914</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.545711</td>
      <td>0.705414</td>
      <td>0.642829</td>
      <td>0.593644</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>20</td>
      <td>0.526595</td>
      <td>0.707571</td>
      <td>0.642755</td>
      <td>0.596481</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>21</td>
      <td>0.523984</td>
      <td>0.710317</td>
      <td>0.643543</td>
      <td>0.594211</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>22</td>
      <td>0.523142</td>
      <td>0.712219</td>
      <td>0.643631</td>
      <td>0.594779</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>23</td>
      <td>0.514355</td>
      <td>0.713436</td>
      <td>0.644370</td>
      <td>0.595062</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>24</td>
      <td>0.514707</td>
      <td>0.714922</td>
      <td>0.644555</td>
      <td>0.597333</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>25</td>
      <td>0.510662</td>
      <td>0.715519</td>
      <td>0.645192</td>
      <td>0.597333</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>26</td>
      <td>0.513145</td>
      <td>0.716319</td>
      <td>0.644894</td>
      <td>0.598468</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>27</td>
      <td>0.513599</td>
      <td>0.716687</td>
      <td>0.644915</td>
      <td>0.597616</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>28</td>
      <td>0.511941</td>
      <td>0.716802</td>
      <td>0.644842</td>
      <td>0.597900</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>29</td>
      <td>0.510378</td>
      <td>0.716789</td>
      <td>0.644854</td>
      <td>0.597900</td>
      <td>00:01</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">
<p><img src="tst_from_scratch_files/figure-html/cell-14-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="tst_from_scratch_files/figure-html/cell-14-output-4.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="our-tst" class="level2">
<h2 class="anchored" data-anchor-id="our-tst">Our TST</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="tst_from_scratch_files/figure-html/be3be432-d613-4571-b965-654e3149a41d.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Transformer Architecture</figcaption><p></p>
</figure>
</div>
<p>The diagram above illustrates the Transformer architecture as presented in the “Attention is All You Need” paper. The breakthrough in this architecture is the <a href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html">Multi-Head Attention</a>. The idea behind Attention is that if your model can focus on the most important parts of a long sequence, it can perform better without being affected by noise.</p>
<p>How does it work? Well, in my experience, when we are not very familiar with a new architecture, we shouldn’t focus too much on understanding every detail of the architecture. I spent a lot of time reading various tutorials, trying to grasp the clever idea behind this, only to realize that I still didn’t know how to apply it to a real case. I will attempt to cover building Self-Attention from scratch in a future blog post. However, in this one, we will start by learning how to use the Self-Attention module from PyTorch.</p>
<p>What do we need to pay attention to here? Mainly the shapes of the input and output. For our specific application, we will use Self-Attention, which treats all three parameters (query, key, and value) as the same tensor, and preserves the shape of the output.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="tst_from_scratch_files/figure-html/e204e34e-0750-4937-b78f-3ee0392c0b48.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Our simplest Transformer model</figcaption><p></p>
</figure>
</div>
<p>We will begin by constructing the simplest Transformer model, which consists of a <code>Self-Attention</code> layer stacked with a Linear Layer that adapts to the number of classification outputs.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> OurTST(Module):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, c_in, c_out, seq_len):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.c_in, <span class="va">self</span>.c_out, <span class="va">self</span>.seq_len <span class="op">=</span> c_in, c_out, seq_len</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.encoder <span class="op">=</span> nn.MultiheadAttention(embed_dim<span class="op">=</span>c_in, num_heads<span class="op">=</span><span class="dv">1</span>, batch_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Linear(seq_len<span class="op">*</span>c_in, c_out)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        o <span class="op">=</span> x.swapaxes(<span class="dv">1</span>,<span class="dv">2</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        o <span class="op">=</span> <span class="va">self</span>.encoder(o,o,o)[<span class="dv">0</span>]</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        o <span class="op">=</span> o.reshape(o.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>        o <span class="op">=</span> <span class="va">self</span>.head(o)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> o</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> OurTST(c_in, c_out, seq_len)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>OurTST(
  (encoder): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=144, out_features=144, bias=True)
  )
  (head): Linear(in_features=8928, out_features=2, bias=True)
)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>evaluate_model(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>roc_auc_score</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.695951</td>
      <td>0.692411</td>
      <td>0.525592</td>
      <td>0.511635</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.692179</td>
      <td>0.691621</td>
      <td>0.543148</td>
      <td>0.527242</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.689011</td>
      <td>0.690405</td>
      <td>0.564887</td>
      <td>0.538593</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.683291</td>
      <td>0.689369</td>
      <td>0.580379</td>
      <td>0.559308</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.667550</td>
      <td>0.685884</td>
      <td>0.605005</td>
      <td>0.576334</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.645704</td>
      <td>0.693245</td>
      <td>0.613381</td>
      <td>0.590238</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0.627285</td>
      <td>0.691571</td>
      <td>0.643158</td>
      <td>0.608400</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0.600961</td>
      <td>0.693096</td>
      <td>0.658148</td>
      <td>0.619467</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.583125</td>
      <td>0.697477</td>
      <td>0.668006</td>
      <td>0.624291</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0.572355</td>
      <td>0.708262</td>
      <td>0.670622</td>
      <td>0.627696</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0.562850</td>
      <td>0.705158</td>
      <td>0.676077</td>
      <td>0.632804</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>11</td>
      <td>0.551437</td>
      <td>0.707944</td>
      <td>0.677232</td>
      <td>0.633655</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>12</td>
      <td>0.538641</td>
      <td>0.713020</td>
      <td>0.678321</td>
      <td>0.633655</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>13</td>
      <td>0.535401</td>
      <td>0.724980</td>
      <td>0.676643</td>
      <td>0.637344</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>14</td>
      <td>0.527875</td>
      <td>0.725295</td>
      <td>0.681552</td>
      <td>0.636493</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>15</td>
      <td>0.517574</td>
      <td>0.727690</td>
      <td>0.680577</td>
      <td>0.636209</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>16</td>
      <td>0.514068</td>
      <td>0.735151</td>
      <td>0.680730</td>
      <td>0.641033</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>17</td>
      <td>0.507436</td>
      <td>0.740215</td>
      <td>0.681385</td>
      <td>0.638479</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>18</td>
      <td>0.502690</td>
      <td>0.744097</td>
      <td>0.683104</td>
      <td>0.636493</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>19</td>
      <td>0.493814</td>
      <td>0.750489</td>
      <td>0.681456</td>
      <td>0.640749</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>20</td>
      <td>0.489252</td>
      <td>0.754481</td>
      <td>0.680600</td>
      <td>0.639047</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>21</td>
      <td>0.495050</td>
      <td>0.753937</td>
      <td>0.682021</td>
      <td>0.639330</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>22</td>
      <td>0.489492</td>
      <td>0.759691</td>
      <td>0.681429</td>
      <td>0.638479</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>23</td>
      <td>0.483442</td>
      <td>0.760909</td>
      <td>0.681763</td>
      <td>0.641033</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>24</td>
      <td>0.475726</td>
      <td>0.761265</td>
      <td>0.682467</td>
      <td>0.640182</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>25</td>
      <td>0.477890</td>
      <td>0.763207</td>
      <td>0.682449</td>
      <td>0.640465</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>26</td>
      <td>0.473845</td>
      <td>0.763524</td>
      <td>0.682148</td>
      <td>0.639898</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>27</td>
      <td>0.470921</td>
      <td>0.763945</td>
      <td>0.682003</td>
      <td>0.638763</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>28</td>
      <td>0.484390</td>
      <td>0.764295</td>
      <td>0.681981</td>
      <td>0.639047</td>
      <td>00:01</td>
    </tr>
    <tr>
      <td>29</td>
      <td>0.471722</td>
      <td>0.764313</td>
      <td>0.681952</td>
      <td>0.639047</td>
      <td>00:01</td>
    </tr>
  </tbody>
</table>
</div>
<div class="cell-output cell-output-display">
<p><img src="tst_from_scratch_files/figure-html/cell-18-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="tst_from_scratch_files/figure-html/cell-18-output-4.png" class="img-fluid"></p>
</div>
</div>
<p>Well, our model outperforms the LSTM model and not far behind the TST model</p>
<p>(To be continued): I will update the model until it reaches the performance of the TST Model, so stay tuned!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>